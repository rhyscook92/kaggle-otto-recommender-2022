{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1eA9IPu0ct5BBp8Z8775IN8wRL0-8ECc6","timestamp":1672445355725},{"file_id":"1Y9trOoIWI7h8XxAt4XWoxIajg8p2hXE0","timestamp":1670368163491}],"machine_shape":"hm","authorship_tag":"ABX9TyO2K83peKd31z5JbqrcMlrN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["# Use the lightgbm models to score the 200 candidates #"],"metadata":{"id":"9swc8dyeFIS6"}},{"cell_type":"code","source":["local = False\n","if local:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  %cd /content/drive/MyDrive/'Kaggle Otto Reccommender'/data\n","  path_to_module = '/content/drive/MyDrive/Kaggle Otto Reccommender/'\n","else:\n","  !mkdir /my_mnt_dir\n","  !google-drive-ocamlfuse /my_mnt_dir\n","  %cd /my_mnt_dir/'Kaggle Otto Reccommender'/data\n","  path_to_module = '/my_mnt_dir/Kaggle Otto Reccommender/'\n","\n","import sys    \n","sys.path.append(path_to_module)"],"metadata":{"id":"rgw3DUBDx7hN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install lightgbm\n","!pip install fastparquet\n","!pip install polars"],"metadata":{"id":"X1mfpfJmv4y6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","import numpy as np\n","import pandas as pd\n","import gc\n","from tqdm import tqdm\n","from copy import deepcopy\n","import polars as pl\n","\n","import lightgbm as lgbm\n","from otto_utils import create_sub"],"metadata":{"id":"bbpCdPcQOMqe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Lightgbm inference functions"],"metadata":{"id":"h_FwSfln38B3"}},{"cell_type":"code","source":["def inference(dtrain_list, recall_type, folds, features):\n","  for fold in range(0, folds):\n","    if fold == 0:\n","      preds = collect_preds(dtrain_list, recall_type, fold, features)\n","    else:\n","      preds += collect_preds(dtrain_list, recall_type, fold, features)\n","  preds = preds / folds\n","\n","  return preds\n","\n","def collect_preds(dtrain_list, recall_type, fold, features):\n","  for i, dtrain_item in enumerate(tqdm(dtrain_list)):\n","    model_file = f'../models/lgbm_models/{recall_type}_{fold}.lgbm'\n","    model = lgbm.Booster(model_file=model_file)\n","    dtrain_item = dtrain_item.loc[:, features]\n","    print(dtrain_item)\n","    preds_chunk = model.predict(dtrain_item)\n","    if i == 0:\n","      preds = preds_chunk\n","    else:\n","      preds = np.append(preds, preds_chunk)\n","\n","  return preds\n","\n","def get_top_20_df(preds, training_data, return_all=True):\n","  predictions = training_data[['session','aid']].copy()\n","  predictions['preds'] = preds\n","  predictions.sort_values(by=['session', 'preds'], ascending=[True, False], inplace=True)\n","  predictions['n'] = predictions.groupby('session').cumcount() + 1\n","  if return_all:\n","    return predictions\n","  else:\n","    return predictions.loc[predictions['n'] <= 20]\n","\n","  return submitted_predictions"],"metadata":{"id":"bvv7dW6gH8Eg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_to_training_data = './test_training_data'\n","training_data = pl.read_parquet(f'{path_to_training_data}/training_data.parquet')\n","# Quick fix to a column that was calculated incorrectly...\n","training_data = training_data.with_column(((pl.col('percent_of_test_weeks_interacted') * 4) / (3)).alias('percent_of_test_weeks_interacted'))\n","training_data = training_data.to_pandas()"],"metadata":{"id":"Dspprue04TdQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for column in training_data.columns:\n","  if training_data[column].dtype in ('Int32', 'float64', 'Int16'):\n","    training_data[column] = training_data[column].astype('float32')\n","training_data.replace([np.inf, -np.inf], np.NaN, inplace=True)\n","training_data.shape"],"metadata":{"id":"4m63Rotif7-C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aids_and_sessions = training_data[['session','aid']]\n","features = [feature for feature in training_data.columns if feature not in ['session', 'aid']]\n","dtrain_list = []\n","sessions = training_data['session'].unique()\n","session_lists = [np_array.tolist() for np_array in np.array_split(np.array(sessions), 10 ) ]\n","\n","for session_list in tqdm(session_lists):\n","  dtrain_list.append(training_data.query(f'session in {session_list}').copy())\n","  training_data = training_data.loc[~training_data.session.isin(session_list)]\n","\n","folds=1\n","del training_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t4-2mcw0231V","executionInfo":{"status":"ok","timestamp":1675012486608,"user_tz":0,"elapsed":287372,"user":{"displayName":"Rhys Cook","userId":"01185162891853889189"}},"outputId":"16c6647a-2a96-4d9d-c1ba-4ceb20c999b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [04:45<00:00, 28.52s/it]\n"]}]},{"cell_type":"markdown","source":["Clicks booster"],"metadata":{"id":"rFrPFulULC6x"}},{"cell_type":"code","source":["#Clicks\n","click_preds = inference(dtrain_list, 'clicks', folds=1, features=features)\n","clicks_df = get_top_20_df(click_preds, aids_and_sessions, return_all=True)\n","clicks_df['n'] = clicks_df['n'].astype('int16')\n","subset = clicks_df.loc[:, ['session', 'aid', 'n']]\n","subset = subset.reset_index(drop=True)\n","subset.to_feather(f'{path_to_training_data}/lgb_clicks_df.feather')"],"metadata":{"id":"mhFef2nuRciC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Carts\n","cart_preds = inference(dtrain_list, 'carts', folds=5, features=features)\n","carts_df = get_top_20_df(cart_preds, aids_and_sessions, return_all=True)\n","carts_df['n'] = carts_df['n'].astype('int16')\n","subset = carts_df.loc[:, ['session', 'aid', 'n']]\n","subset = subset.reset_index(drop=True)\n","subset.to_feather(f'{path_to_training_data}/lgb_carts_df.feather')"],"metadata":{"id":"DL7a9eFldGRl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Orders\n","order_preds = inference(dtrain_list, 'orders', folds=6, features=features)\n","orders_df = get_top_20_df(order_preds, aids_and_sessions, return_all=True)\n","orders_df['n'] = orders_df['n'].astype('int16')\n","subset = orders_df.loc[:, ['session', 'aid', 'n']]\n","subset = subset.reset_index(drop=True)\n","subset.to_feather(f'{path_to_training_data}/lgb_orders_df.feather')"],"metadata":{"id":"jPuw-0FIf2E4"},"execution_count":null,"outputs":[]}]}